{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06a1eb86-bf81-42ce-86cc-cad781277805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- s.no: long (nullable = true)\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- bonus: long (nullable = true)\n",
      "\n",
      "+----+-------------+----------+-----+------+---+-----+\n",
      "|s.no|employee_name|department|state|salary|age|bonus|\n",
      "+----+-------------+----------+-----+------+---+-----+\n",
      "|1   |James        |Sales     |NY   |90000 |34 |10000|\n",
      "|2   |Michael      |Sales     |NY   |86000 |56 |20000|\n",
      "|3   |Robert       |Sales     |CA   |81000 |30 |23000|\n",
      "|2   |Michael      |Sales     |NY   |86000 |56 |20000|\n",
      "|3   |Robert       |Sales     |CA   |81000 |30 |23000|\n",
      "|4   |Maria        |Finance   |CA   |90000 |24 |23000|\n",
      "+----+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "simpleData = [(1,\"James\",\"Sales\",\"NY\",90000,34,10000), \\\n",
    "    (2,\"Michael\",\"Sales\",\"NY\",86000,56,20000), \\\n",
    "    (3,\"Robert\",\"Sales\",\"CA\",81000,30,23000), \\\n",
    "    (2,\"Michael\",\"Sales\",\"NY\",86000,56,20000), \\\n",
    "    (3,\"Robert\",\"Sales\",\"CA\",81000,30,23000),\n",
    "    (4,\"Maria\",\"Finance\",\"CA\",90000,24,23000), \\\n",
    "\n",
    "  ]\n",
    "columns= [\"s.no\",\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder.appName(\"spark_sort\").getOrCreate()\n",
    "df1 = spark.createDataFrame(data = simpleData, schema = columns)\n",
    "df1.printSchema()\n",
    "df1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c42c74df-ac3e-4596-9878-14382e134675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- s.no: long (nullable = true)\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- bonus: long (nullable = true)\n",
      "\n",
      "+----+-------------+----------+-----+------+---+-----+\n",
      "|s.no|employee_name|department|state|salary|age|bonus|\n",
      "+----+-------------+----------+-----+------+---+-----+\n",
      "|5   |Raman        |Finance   |CA   |99000 |40 |24000|\n",
      "|6   |Scott        |Finance   |NY   |83000 |36 |19000|\n",
      "|7   |Jen          |Finance   |NY   |79000 |53 |15000|\n",
      "|8   |Jeff         |Marketing |CA   |80000 |25 |18000|\n",
      "|5   |Raman        |Finance   |CA   |99000 |40 |24000|\n",
      "|6   |Scott        |Finance   |NY   |83000 |36 |19000|\n",
      "|9   |Kumar        |Marketing |NY   |91000 |50 |21000|\n",
      "+----+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "simpleData = [(5,\"Raman\",\"Finance\",\"CA\",99000,40,24000), \\\n",
    "    (6,\"Scott\",\"Finance\",\"NY\",83000,36,19000), \\\n",
    "    (7,\"Jen\",\"Finance\",\"NY\",79000,53,15000), \\\n",
    "    (8,\"Jeff\",\"Marketing\",\"CA\",80000,25,18000), \\\n",
    "    (5,\"Raman\",\"Finance\",\"CA\",99000,40,24000), \\\n",
    "    (6,\"Scott\",\"Finance\",\"NY\",83000,36,19000), \\\n",
    "    (9,\"Kumar\",\"Marketing\",\"NY\",91000,50,21000) \\\n",
    "\n",
    "  ]\n",
    "columns= [\"s.no\",\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder.appName(\"spark_sort\").getOrCreate()\n",
    "df2 = spark.createDataFrame(data = simpleData, schema = columns)\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf6a17a7-de43-4247-a6f9-c4e262583781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+----------+-----+------+---+-----+\n",
      "|s.no|employee_name|department|state|salary|age|bonus|\n",
      "+----+-------------+----------+-----+------+---+-----+\n",
      "|   1|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|   2|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|   3|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|   2|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|   3|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|   4|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|   5|        Raman|   Finance|   CA| 99000| 40|24000|\n",
      "|   6|        Scott|   Finance|   NY| 83000| 36|19000|\n",
      "|   7|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|   8|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|   5|        Raman|   Finance|   CA| 99000| 40|24000|\n",
      "|   6|        Scott|   Finance|   NY| 83000| 36|19000|\n",
      "|   9|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "+----+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# union \n",
    "from pyspark.sql.functions import *\n",
    "df = df1.union(df2)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7f6d493-5e2a-43c3-b4fb-793983c8e969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+----------+-----+------+---+-----+\n",
      "|s.no|employee_name|department|state|salary|age|bonus|\n",
      "+----+-------------+----------+-----+------+---+-----+\n",
      "|   1|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|   2|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|   3|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|   2|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|   3|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|   4|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|   5|        Raman|   Finance|   CA| 99000| 40|24000|\n",
      "|   6|        Scott|   Finance|   NY| 83000| 36|19000|\n",
      "|   7|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|   8|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|   5|        Raman|   Finance|   CA| 99000| 40|24000|\n",
      "|   6|        Scott|   Finance|   NY| 83000| 36|19000|\n",
      "|   9|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "+----+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unionAll\n",
    "#from pyspark.sql.functions import unionAll\n",
    "df3 = df1.unionAll(df2)\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8eabc13d-242a-4128-bbac-a9c979f087c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+----------+-----+------+---+-----+\n",
      "|s.no|employee_name|department|state|salary|age|bonus|\n",
      "+----+-------------+----------+-----+------+---+-----+\n",
      "|   1|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|   2|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|   3|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|   4|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|   5|        Raman|   Finance|   CA| 99000| 40|24000|\n",
      "|   6|        Scott|   Finance|   NY| 83000| 36|19000|\n",
      "|   7|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|   8|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|   9|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "+----+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if you want to remove the duplicate rows by discent\n",
    "df3.distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b92197c-a234-4b9f-a279-cfb18a7b262b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+----------+-----+------+---+-----+\n",
      "|s.no|employee_name|department|state|salary|age|bonus|\n",
      "+----+-------------+----------+-----+------+---+-----+\n",
      "|   1|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|   2|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|   3|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|   4|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|   5|        Raman|   Finance|   CA| 99000| 40|24000|\n",
      "|   6|        Scott|   Finance|   NY| 83000| 36|19000|\n",
      "|   7|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|   8|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|   9|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "+----+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if you want to remove the duplicate rows by dropDuplicates\n",
    "df3.dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "228b5d8a-d0f4-457a-8448-185d25e7f79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+----------+-----+------+---+-----+\n",
      "|s.no|employee_name|department|state|salary|age|bonus|\n",
      "+----+-------------+----------+-----+------+---+-----+\n",
      "|   4|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|   8|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|   1|        James|     Sales|   NY| 90000| 34|10000|\n",
      "+----+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop duplicate on department column data\n",
    "df3.dropDuplicates(['department']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99432654-fa7f-44ac-9c8f-b2d3f4e6206e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+----------+-----+------+---+-----+\n",
      "|s.no|employee_name|department|state|salary|age|bonus|\n",
      "+----+-------------+----------+-----+------+---+-----+\n",
      "|   1|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|   2|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|   3|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|   4|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|   5|        Raman|   Finance|   CA| 99000| 40|24000|\n",
      "|   6|        Scott|   Finance|   NY| 83000| 36|19000|\n",
      "|   7|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|   8|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|   9|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "+----+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop duplicate on department column data\n",
    "df3.dropDuplicates(['s.no']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13895208-c856-46fb-9750-72e2868d23f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
