{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40e2a79c-03fb-4969-97ee-72e87f582bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\ranga pavan\\anaconda3\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\ranga pavan\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "392313f9-19fc-4761-b02a-d4901ab2c003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "pyspark.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d913141-e1b3-44f7-8609-087d989db985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"SparkByExemples\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b448e2c-933f-4fb5-a292-d650a3d34dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x00000217EAB654D0>\n",
      "RDD count: 6\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"Spark_Exemple\").getOrCreate()\n",
    "print(spark)\n",
    "rdd = spark.sparkContext.parallelize([1,2,3,4,5,6])\n",
    "print(\"RDD count:\",+rdd.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836ae92e-9f36-42c3-8e85-ac66c672d8a9",
   "metadata": {},
   "source": [
    "## Creating PySpark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb80686c-3d87-423a-a0b8-948305d732a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x00000217EAB654D0>\n",
      "+---------+----------+--------+----------+------+------+\n",
      "|firstname|middlename|lastname|       dob|gender|salary|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "|    James|          |   Smith|1991-04-01|     M|  3000|\n",
      "|  Michael|      Rose|        |2000-05-19|     M|  4000|\n",
      "|   Robert|          |Williams|1978-09-05|     M|  4000|\n",
      "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|\n",
      "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('local[2]').appName(\"Spark_Exe\").getOrCreate()\n",
    "print(spark)\n",
    "data = [('James','','Smith','1991-04-01','M',3000),\n",
    "  ('Michael','Rose','','2000-05-19','M',4000),\n",
    "  ('Robert','','Williams','1978-09-05','M',4000),\n",
    "  ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
    "  ('Jen','Mary','Brown','1980-02-17','F',-1)\n",
    "]\n",
    "\n",
    "columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"] \n",
    "df = spark.createDataFrame(data = data,schema = columns)\n",
    "df.show() # to get the default 20 rows of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97854ccc-022d-40be-b3a6-1c75ca7a6770",
   "metadata": {},
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a28698-8091-4cc5-9667-305fc6916d02",
   "metadata": {},
   "source": [
    "### Change the column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95f591b9-25c6-4dee-b8f5-c14fca3ecc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+\n",
      "|firstname|middlename|   LName|       dob|gender|salary|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "|    James|          |   Smith|1991-04-01|     M|  3000|\n",
      "|  Michael|      Rose|        |2000-05-19|     M|  4000|\n",
      "|   Robert|          |Williams|1978-09-05|     M|  4000|\n",
      "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|\n",
      "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1= df.withColumnRenamed(\"lastname\",\"LName\")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d3a657c-b4be-4c03-bd31-8b42d76dc5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- LName: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff518a1-94bd-4567-85d5-c25846032016",
   "metadata": {},
   "source": [
    "### Creating DataFrame with nestered columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9edb0ab-e7e1-40ed-a563-973d2c6abfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- Lastname: string (nullable = true)\n",
      " |-- DOB: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n",
      "+--------------------+----------+------+------+\n",
      "|                Name|       DOB|Gender|Salary|\n",
      "+--------------------+----------+------+------+\n",
      "|    {James, , Smith}|1991-04-01|     M|  3000|\n",
      "|   {Michael, Rose, }|2000-05-19|     M|  4000|\n",
      "|{Robert, , Williams}|1978-09-05|     M|  4000|\n",
      "|{Maria, Anne, Jones}|1967-12-01|     F|  4000|\n",
      "|  {Jen, Mary, Brown}|1980-02-17|     F|    -1|\n",
      "+--------------------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType, StructType, StructField,IntegerType\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Spark_Exe\").getOrCreate()\n",
    "data2 = dataDF = [(('James','','Smith'),'1991-04-01','M',3000),\n",
    "  (('Michael','Rose',''),'2000-05-19','M',4000),\n",
    "  (('Robert','','Williams'),'1978-09-05','M',4000),\n",
    "  (('Maria','Anne','Jones'),'1967-12-01','F',4000),\n",
    "  (('Jen','Mary','Brown'),'1980-02-17','F',-1)\n",
    "]\n",
    "schema2 = StructType([\n",
    "    StructField(\"Name\", StructType([\n",
    "        StructField(\"firstname\",StringType()),\n",
    "        StructField(\"middlename\",StringType()),\n",
    "        StructField(\"Lastname\",StringType())\n",
    "    ])),\n",
    "    StructField(\"DOB\",StringType()),\n",
    "    StructField(\"Gender\",StringType()),\n",
    "    StructField(\"Salary\", IntegerType())\n",
    "])\n",
    "df2 = spark.createDataFrame(data = data2 , schema = schema2)\n",
    "df2.printSchema()\n",
    "df2.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5b3bf2-ccc8-4e2a-b677-c559ec56777c",
   "metadata": {},
   "source": [
    "## Using PySpark StructType – To rename a nested column in Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d90aab70-32fa-4543-bf3f-e12ab3139ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: struct (nullable = true)\n",
      " |    |-- fname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lname: string (nullable = true)\n",
      " |-- DOB: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "schema3 = StructType([\n",
    "    StructField(\"fname\",StringType()),\n",
    "    StructField(\"middlename\",StringType()),\n",
    "    StructField(\"lname\",StringType())])\n",
    "df2.select(col(\"Name\").cast(schema3),col(\"DOB\"), col(\"Gender\"), col(\"Salary\")).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17f4c0a-b8a5-4bf6-8955-dfe752a015e9",
   "metadata": {},
   "source": [
    "### Using Select – To rename nested elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef6e4c53-efc2-48f0-a504-84d28c253408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fname: string (nullable = true)\n",
      " |-- mname: string (nullable = true)\n",
      " |-- lname: string (nullable = true)\n",
      " |-- DOB: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df2.select(col(\"Name.firstname\").alias(\"fname\"),\n",
    "           col(\"Name.middlename\").alias(\"mname\"),\n",
    "           col(\"Name.lastname\").alias(\"lname\"),\n",
    "           col(\"DOB\"),\n",
    "           col(\"Gender\"),\n",
    "           col(\"Salary\")).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bebf7ca-2846-4265-aa0c-ed60b429586c",
   "metadata": {},
   "source": [
    "### Using PySpark DataFrame withColumn – To rename nested columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24c128ca-f39d-48c0-8a52-99ba78fee416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DOB: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      " |-- fname: string (nullable = true)\n",
      " |-- mname: string (nullable = true)\n",
      " |-- lname: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = df2.withColumn(\"fname\",col(\"Name.firstname\")).withColumn(\"mname\",col(\"Name.middlename\")).withColumn(\"lname\",col(\"Name.lastname\")).drop(\"Name\")\n",
    "df3.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2889443-2d44-4112-aa8a-7e6c04853435",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+-------+-----+--------+\n",
      "|       DOB|Gender|Salary|  fname|mname|   lname|\n",
      "+----------+------+------+-------+-----+--------+\n",
      "|1991-04-01|     M|  3000|  James|     |   Smith|\n",
      "|2000-05-19|     M|  4000|Michael| Rose|        |\n",
      "|1978-09-05|     M|  4000| Robert|     |Williams|\n",
      "|1967-12-01|     F|  4000|  Maria| Anne|   Jones|\n",
      "|1980-02-17|     F|    -1|    Jen| Mary|   Brown|\n",
      "+----------+------+------+-------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaad3f8-41d2-4b96-87f1-e2309eee6f4e",
   "metadata": {},
   "source": [
    "### Using toDF() – To change all columns in a PySpark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84053c24-8bde-467b-a455-b49123ad3e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- col1: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- Lastname: string (nullable = true)\n",
      " |-- col2: string (nullable = true)\n",
      " |-- col3: string (nullable = true)\n",
      " |-- col4: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_columns = ['col1','col2','col3','col4']\n",
    "df2.toDF(*new_columns).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0e326c3-1ede-473a-a699-cda72bd9e2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- DateOfBirth: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- DateOfBirth: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary_amount: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- fname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- fname: string (nullable = true)\n",
      " |-- mname: string (nullable = true)\n",
      " |-- lname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- fname: string (nullable = true)\n",
      " |-- mname: string (nullable = true)\n",
      " |-- lname: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- newCol1: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- newCol2: string (nullable = true)\n",
      " |-- newCol3: string (nullable = true)\n",
      " |-- newCol4: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nnot working\\nold_columns = Seq(\"dob\",\"gender\",\"salary\",\"fname\",\"mname\",\"lname\")\\nnew_columns = Seq(\"DateOfBirth\",\"Sex\",\"salary\",\"firstName\",\"middleName\",\"lastName\")\\ncolumnsList = old_columns.zip(new_columns).map(f=>{col(f._1).as(f._2)})\\ndf5 = df4.select(columnsList:_*)\\ndf5.printSchema()\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "dataDF = [(('James','','Smith'),'1991-04-01','M',3000),\n",
    "  (('Michael','Rose',''),'2000-05-19','M',4000),\n",
    "  (('Robert','','Williams'),'1978-09-05','M',4000),\n",
    "  (('Maria','Anne','Jones'),'1967-12-01','F',4000),\n",
    "  (('Jen','Mary','Brown'),'1980-02-17','F',-1)\n",
    "]\n",
    "\n",
    "schema = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "         StructField('dob', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('salary', IntegerType(), True)\n",
    "         ])\n",
    "\n",
    "df = spark.createDataFrame(data = dataDF, schema = schema)\n",
    "df.printSchema()\n",
    "\n",
    "# Example 1\n",
    "df.withColumnRenamed(\"dob\",\"DateOfBirth\").printSchema()\n",
    "# Example 2   \n",
    "df2 = df.withColumnRenamed(\"dob\",\"DateOfBirth\") \\\n",
    "    .withColumnRenamed(\"salary\",\"salary_amount\")\n",
    "df2.printSchema()\n",
    "\n",
    "# Example 3 \n",
    "schema2 = StructType([\n",
    "    StructField(\"fname\",StringType()),\n",
    "    StructField(\"middlename\",StringType()),\n",
    "    StructField(\"lname\",StringType())])\n",
    "    \n",
    "df.select(col(\"name\").cast(schema2),\n",
    "  col(\"dob\"),\n",
    "  col(\"gender\"),\n",
    "  col(\"salary\")) \\\n",
    "    .printSchema()    \n",
    "\n",
    "# Example 4 \n",
    "df.select(col(\"name.firstname\").alias(\"fname\"),\n",
    "  col(\"name.middlename\").alias(\"mname\"),\n",
    "  col(\"name.lastname\").alias(\"lname\"),\n",
    "  col(\"dob\"),col(\"gender\"),col(\"salary\")) \\\n",
    "  .printSchema()\n",
    "  \n",
    "# Example 5\n",
    "df4 = df.withColumn(\"fname\",col(\"name.firstname\")) \\\n",
    "      .withColumn(\"mname\",col(\"name.middlename\")) \\\n",
    "      .withColumn(\"lname\",col(\"name.lastname\")) \\\n",
    "      .drop(\"name\")\n",
    "df4.printSchema()\n",
    "\n",
    "#Example 7\n",
    "newColumns = [\"newCol1\",\"newCol2\",\"newCol3\",\"newCol4\"]\n",
    "df.toDF(*newColumns).printSchema()\n",
    "\n",
    "# Example 6\n",
    "'''\n",
    "not working\n",
    "old_columns = Seq(\"dob\",\"gender\",\"salary\",\"fname\",\"mname\",\"lname\")\n",
    "new_columns = Seq(\"DateOfBirth\",\"Sex\",\"salary\",\"firstName\",\"middleName\",\"lastName\")\n",
    "columnsList = old_columns.zip(new_columns).map(f=>{col(f._1).as(f._2)})\n",
    "df5 = df4.select(columnsList:_*)\n",
    "df5.printSchema()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b000c3ca-91ff-4844-b856-468a63404518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- DateOfBirth: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary_amount: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5= df.withColumnRenamed(\"dob\",\"DateOfBirth\") \\\n",
    "    .withColumnRenamed(\"salary\",\"salary_amount\")\n",
    "df5.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dccc13-3868-4bd1-99d2-5c8ab2d81f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
