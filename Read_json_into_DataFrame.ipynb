{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81712855-ea2c-4867-98e5-fbe0c93f1d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Read_json_into_DataFrame.com\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3465cba-4939-4e7a-88c5-3e37dfaec188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_df',\n",
       " '_jreader',\n",
       " '_set_opts',\n",
       " '_spark',\n",
       " 'csv',\n",
       " 'format',\n",
       " 'jdbc',\n",
       " 'json',\n",
       " 'load',\n",
       " 'option',\n",
       " 'options',\n",
       " 'orc',\n",
       " 'parquet',\n",
       " 'schema',\n",
       " 'table',\n",
       " 'text']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(spark.read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af6d75b3-0506-415a-950c-75c9649fdb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method json in module pyspark.sql.readwriter:\n",
      "\n",
      "json(path: Union[str, List[str], pyspark.rdd.RDD[str]], schema: Union[pyspark.sql.types.StructType, str, NoneType] = None, primitivesAsString: Union[bool, str, NoneType] = None, prefersDecimal: Union[bool, str, NoneType] = None, allowComments: Union[bool, str, NoneType] = None, allowUnquotedFieldNames: Union[bool, str, NoneType] = None, allowSingleQuotes: Union[bool, str, NoneType] = None, allowNumericLeadingZero: Union[bool, str, NoneType] = None, allowBackslashEscapingAnyCharacter: Union[bool, str, NoneType] = None, mode: Optional[str] = None, columnNameOfCorruptRecord: Optional[str] = None, dateFormat: Optional[str] = None, timestampFormat: Optional[str] = None, multiLine: Union[bool, str, NoneType] = None, allowUnquotedControlChars: Union[bool, str, NoneType] = None, lineSep: Optional[str] = None, samplingRatio: Union[str, float, NoneType] = None, dropFieldIfAllNull: Union[bool, str, NoneType] = None, encoding: Optional[str] = None, locale: Optional[str] = None, pathGlobFilter: Union[bool, str, NoneType] = None, recursiveFileLookup: Union[bool, str, NoneType] = None, modifiedBefore: Union[bool, str, NoneType] = None, modifiedAfter: Union[bool, str, NoneType] = None, allowNonNumericNumbers: Union[bool, str, NoneType] = None) -> 'DataFrame' method of pyspark.sql.readwriter.DataFrameReader instance\n",
      "    Loads JSON files and returns the results as a :class:`DataFrame`.\n",
      "    \n",
      "    `JSON Lines <http://jsonlines.org/>`_ (newline-delimited JSON) is supported by default.\n",
      "    For JSON (one record per file), set the ``multiLine`` parameter to ``true``.\n",
      "    \n",
      "    If the ``schema`` parameter is not specified, this function goes\n",
      "    through the input once to determine the input schema.\n",
      "    \n",
      "    .. versionadded:: 1.4.0\n",
      "    \n",
      "    .. versionchanged:: 3.4.0\n",
      "        Supports Spark Connect.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    path : str, list or :class:`RDD`\n",
      "        string represents path to the JSON dataset, or a list of paths,\n",
      "        or RDD of Strings storing JSON objects.\n",
      "    schema : :class:`pyspark.sql.types.StructType` or str, optional\n",
      "        an optional :class:`pyspark.sql.types.StructType` for the input schema or\n",
      "        a DDL-formatted string (For example ``col0 INT, col1 DOUBLE``).\n",
      "    \n",
      "    Other Parameters\n",
      "    ----------------\n",
      "    Extra options\n",
      "        For the extra options, refer to\n",
      "        `Data Source Option <https://spark.apache.org/docs/latest/sql-data-sources-json.html#data-source-option>`_\n",
      "        for the version you use.\n",
      "    \n",
      "        .. # noqa\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Write a DataFrame into a JSON file and read it back.\n",
      "    \n",
      "    >>> import tempfile\n",
      "    >>> with tempfile.TemporaryDirectory() as d:\n",
      "    ...     # Write a DataFrame into a JSON file\n",
      "    ...     spark.createDataFrame(\n",
      "    ...         [{\"age\": 100, \"name\": \"Hyukjin Kwon\"}]\n",
      "    ...     ).write.mode(\"overwrite\").format(\"json\").save(d)\n",
      "    ...\n",
      "    ...     # Read the JSON file as a DataFrame.\n",
      "    ...     spark.read.json(d).show()\n",
      "    +---+------------+\n",
      "    |age|        name|\n",
      "    +---+------------+\n",
      "    |100|Hyukjin Kwon|\n",
      "    +---+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(spark.read.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c10905b4-a73a-4248-9dcd-7644351af58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "None\n",
      "+-------+---+------+\n",
      "|   Name| id|salary|\n",
      "+-------+---+------+\n",
      "| sreenu|  1| 20000|\n",
      "|   babu|  2| 30000|\n",
      "|vennela|  3| 25000|\n",
      "| janavi|  1| 20000|\n",
      "+-------+---+------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# reading the json file\n",
    "df = spark.read.json(path='sample5.json')\n",
    "print(df.printSchema())\n",
    "print(df.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a49a6f75-f25a-452a-b9a5-c70e660de171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- number: string (nullable = true)\n",
      "\n",
      "None\n",
      "+---+---------+------+--------+----------+\n",
      "|age|firstName|gender|lastName|    number|\n",
      "+---+---------+------+--------+----------+\n",
      "| 28|      Joe|  male| Jackson|7349282382|\n",
      "| 32|    James|  male|   Smith|5678568567|\n",
      "| 24|    Emily|female|   Jones| 456754675|\n",
      "+---+---------+------+--------+----------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# reading the json file\n",
    "df = spark.read.json(path='sample4.json',multiLine=True)\n",
    "print(df.printSchema())\n",
    "print(df.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dc6d00a-a251-4c79-8e0d-9dc279de5d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- color: string (nullable = true)\n",
      " |-- value: string (nullable = true)\n",
      "\n",
      "None\n",
      "+-------+-----+\n",
      "|  color|value|\n",
      "+-------+-----+\n",
      "|    red| #f00|\n",
      "|  green| #0f0|\n",
      "|   blue| #00f|\n",
      "|   cyan| #0ff|\n",
      "|magenta| #f0f|\n",
      "| yellow| #ff0|\n",
      "|  black| #000|\n",
      "+-------+-----+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# reading the json file\n",
    "df = spark.read.json(path='json_files/sample3.json',multiLine=True)\n",
    "print(df.printSchema())\n",
    "print(df.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6891d9b8-8fd9-4433-89e1-762adcc767e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- number: string (nullable = true)\n",
      "\n",
      "None\n",
      "+---+---------+------+--------+----------+\n",
      "|age|firstName|gender|lastName|number    |\n",
      "+---+---------+------+--------+----------+\n",
      "|24 |seenu    |male  |velugu  |7349282382|\n",
      "|25 |babu     |male  |velugu  |5678568567|\n",
      "|24 |vennela  |female|roy     |456754675 |\n",
      "|28 |Joe      |male  |Jackson |7349282382|\n",
      "|32 |James    |male  |Smith   |5678568567|\n",
      "|24 |Emily    |female|Jones   |456754675 |\n",
      "+---+---------+------+--------+----------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# reading the multiple JSON file is possible when the schema of all JSON files is the same\n",
    "df2 = spark.read.json(path=['json_files/sample5.json','json_files/sample4.json'],multiLine=True)\n",
    "print(df2.printSchema())\n",
    "print(df2.show(truncate=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afe0647a-c083-4613-bb64-18e6c7bdb67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- number: long (nullable = true)\n",
      "\n",
      "None\n",
      "+---+---------+------+--------+------+\n",
      "|age|firstName|gender|lastName|number|\n",
      "+---+---------+------+--------+------+\n",
      "|24 |seenu    |male  |velugu  |NULL  |\n",
      "|25 |babu     |male  |velugu  |NULL  |\n",
      "|24 |vennela  |female|roy     |NULL  |\n",
      "|28 |Joe      |male  |Jackson |NULL  |\n",
      "|32 |James    |male  |Smith   |NULL  |\n",
      "|24 |Emily    |female|Jones   |NULL  |\n",
      "+---+---------+------+--------+------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# change the date types of columns\n",
    "# Change the schema of data frame\n",
    "from pyspark.sql.types import StructType, IntegerType, StringType,LongType\n",
    "schema = StructType().add(field = 'age', data_type = IntegerType()) \\\n",
    "                    .add(field = 'firstName', data_type = StringType()) \\\n",
    "                    .add(field = 'gender', data_type = StringType()) \\\n",
    "                    .add(field = 'lastName', data_type = StringType()) \\\n",
    "                    .add(field = 'number', data_type = LongType()) \n",
    "df2 = spark.read.json(path=['json_files/sample5.json','json_files/sample4.json'],multiLine=True,schema = schema)\n",
    "print(df2.printSchema())\n",
    "print(df2.show(truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd419750-83eb-48f7-95de-9225067953ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the json files from folder\n",
    "# syntax =spark.read.json('folder_path/*.josn')\n",
    "df3 = spark.read.json(path = 'json_files/json_folder/*.json',multiLine=True)\n",
    "print(df3.printSchema())\n",
    "print(df3.show(truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039081fa-dd8d-44bf-930c-75fad358a3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
