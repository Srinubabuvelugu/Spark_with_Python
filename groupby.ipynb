{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "622fb6d6-19c6-4e74-a293-7af5e11fc268",
   "metadata": {},
   "source": [
    "## groupBy function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e5eb24d-8cd5-4b7f-af9b-a6233e6f1949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: struct (nullable = true)\n",
      " |    |-- Firstname: string (nullable = true)\n",
      " |    |-- Middlename: string (nullable = true)\n",
      " |    |-- Lastname: string (nullable = true)\n",
      " |-- Languages: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      "\n",
      "+----------------------+------------------+-------+------+\n",
      "|Name                  |Languages         |Country|Gender|\n",
      "+----------------------+------------------+-------+------+\n",
      "|{James, , Smith}      |[Java, Scala, C++]|OH     |M     |\n",
      "|{Anna, Rose, }        |[Spark, Java, C++]|NY     |F     |\n",
      "|{Julia, , Williams}   |[CSharp, VB]      |OH     |F     |\n",
      "|{Maria, Anne, Jones}  |[CSharp, VB]      |NY     |M     |\n",
      "|{Jen, Mary, Brown}    |[CSharp, VB]      |NY     |M     |\n",
      "|{Mike, Mary, Williams}|[Python, VB]      |OH     |M     |\n",
      "+----------------------+------------------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import StringType, IntegerType, ArrayType\n",
    "\n",
    "data = [\n",
    "    ((\"James\",\"\",\"Smith\"),[\"Java\",\"Scala\",\"C++\"],\"OH\",\"M\"),\n",
    "    ((\"Anna\",\"Rose\",\"\"),[\"Spark\",\"Java\",\"C++\"],\"NY\",\"F\"),\n",
    "    ((\"Julia\",\"\",\"Williams\"),[\"CSharp\",\"VB\"],\"OH\",\"F\"),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "    ((\"Mike\",\"Mary\",\"Williams\"),[\"Python\",\"VB\"],\"OH\",\"M\")\n",
    " ]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"Name\",StructType([\n",
    "        StructField(\"Firstname\",StringType()),\n",
    "        StructField(\"Middlename\", StringType()),\n",
    "        StructField(\"Lastname\", StringType())\n",
    "        ])),\n",
    "    StructField(\"Languages\", ArrayType(StringType())),\n",
    "    StructField(\"Country\", StringType()),\n",
    "    StructField(\"Gender\", StringType())\n",
    "                ])\n",
    "                \n",
    "spark = SparkSession.builder.appName(\"Spark filter\").getOrCreate()\n",
    "\n",
    "df = spark.createDataFrame(data = data, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f24f559-fd21-4d2e-8cc8-0c7a2d979cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|Country|count|\n",
      "+-------+-----+\n",
      "|OH     |3    |\n",
      "|NY     |3    |\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Country').count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3ef7295-8161-4197-9dcc-be103a70c642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+\n",
      "|Country|Gender|count|\n",
      "+-------+------+-----+\n",
      "|OH     |M     |2    |\n",
      "|NY     |F     |1    |\n",
      "|OH     |F     |1    |\n",
      "|NY     |M     |2    |\n",
      "+-------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Country','Gender').count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea44a409-447d-404a-b7d1-a7041b867e06",
   "metadata": {},
   "source": [
    "## groupBy agg() function\n",
    "- Pyspark groupBy agg() function is used to apply more then one aggregate at a time on grouped DataFrame\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "756a0b94-ee7a-4200-a066-67a0a0d11331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x000002405A4109D0>\n",
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "None\n",
      "+---------+----------+--------+----------+------+------+\n",
      "|firstname|middlename|lastname|       dob|gender|salary|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "|    James|          |   Smith|1991-04-01|     M|  3000|\n",
      "|  Michael|      Rose|        |2000-05-19|     M|  4000|\n",
      "|   Robert|          |Williams|1978-09-05|     M|  4000|\n",
      "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|\n",
      "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('local[2]').appName(\"Spark_Exe\").getOrCreate()\n",
    "print(spark)\n",
    "data = [('James','','Smith','1991-04-01','M',3000),\n",
    "  ('Michael','Rose','','2000-05-19','M',4000),\n",
    "  ('Robert','','Williams','1978-09-05','M',4000),\n",
    "  ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
    "  ('Jen','Mary','Brown','1980-02-17','F',-1)\n",
    "]\n",
    "\n",
    "columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"] \n",
    "df2 = spark.createDataFrame(data = data,schema = columns)\n",
    "print(df2.printSchema())\n",
    "df2.show() # to get the default 20 rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdaad828-550f-4fd8-8e00-f1f6f1cc4176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method agg in module pyspark.sql.group:\n",
      "\n",
      "agg(*exprs: Union[pyspark.sql.column.Column, Dict[str, str]]) -> pyspark.sql.dataframe.DataFrame method of pyspark.sql.group.GroupedData instance\n",
      "    Compute aggregates and returns the result as a :class:`DataFrame`.\n",
      "    \n",
      "    The available aggregate functions can be:\n",
      "    \n",
      "    1. built-in aggregation functions, such as `avg`, `max`, `min`, `sum`, `count`\n",
      "    \n",
      "    2. group aggregate pandas UDFs, created with :func:`pyspark.sql.functions.pandas_udf`\n",
      "    \n",
      "       .. note:: There is no partial aggregation with group aggregate UDFs, i.e.,\n",
      "           a full shuffle is required. Also, all the data of a group will be loaded into\n",
      "           memory, so the user should be aware of the potential OOM risk if data is skewed\n",
      "           and certain groups are too large to fit in memory.\n",
      "    \n",
      "       .. seealso:: :func:`pyspark.sql.functions.pandas_udf`\n",
      "    \n",
      "    If ``exprs`` is a single :class:`dict` mapping from string to string, then the key\n",
      "    is the column to perform aggregation on, and the value is the aggregate function.\n",
      "    \n",
      "    Alternatively, ``exprs`` can also be a list of aggregate :class:`Column` expressions.\n",
      "    \n",
      "    .. versionadded:: 1.3.0\n",
      "    \n",
      "    .. versionchanged:: 3.4.0\n",
      "        Supports Spark Connect.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    exprs : dict\n",
      "        a dict mapping from column name (string) to aggregate functions (string),\n",
      "        or a list of :class:`Column`.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Built-in aggregation functions and group aggregate pandas UDFs cannot be mixed\n",
      "    in a single call to this function.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from pyspark.sql import functions as sf\n",
      "    >>> from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
      "    >>> df = spark.createDataFrame(\n",
      "    ...      [(2, \"Alice\"), (3, \"Alice\"), (5, \"Bob\"), (10, \"Bob\")], [\"age\", \"name\"])\n",
      "    >>> df.show()\n",
      "    +---+-----+\n",
      "    |age| name|\n",
      "    +---+-----+\n",
      "    |  2|Alice|\n",
      "    |  3|Alice|\n",
      "    |  5|  Bob|\n",
      "    | 10|  Bob|\n",
      "    +---+-----+\n",
      "    \n",
      "    Group-by name, and count each group.\n",
      "    \n",
      "    >>> df.groupBy(df.name)\n",
      "    GroupedData[grouping...: [name...], value: [age: bigint, name: string], type: GroupBy]\n",
      "    \n",
      "    >>> df.groupBy(df.name).agg({\"*\": \"count\"}).sort(\"name\").show()\n",
      "    +-----+--------+\n",
      "    | name|count(1)|\n",
      "    +-----+--------+\n",
      "    |Alice|       2|\n",
      "    |  Bob|       2|\n",
      "    +-----+--------+\n",
      "    \n",
      "    Group-by name, and calculate the minimum age.\n",
      "    \n",
      "    >>> df.groupBy(df.name).agg(sf.min(df.age)).sort(\"name\").show()\n",
      "    +-----+--------+\n",
      "    | name|min(age)|\n",
      "    +-----+--------+\n",
      "    |Alice|       2|\n",
      "    |  Bob|       5|\n",
      "    +-----+--------+\n",
      "    \n",
      "    Same as above but uses pandas UDF.\n",
      "    \n",
      "    >>> @pandas_udf('int', PandasUDFType.GROUPED_AGG)  # doctest: +SKIP\n",
      "    ... def min_udf(v):\n",
      "    ...     return v.min()\n",
      "    ...\n",
      "    >>> df.groupBy(df.name).agg(min_udf(df.age)).sort(\"name\").show()  # doctest: +SKIP\n",
      "    +-----+------------+\n",
      "    | name|min_udf(age)|\n",
      "    +-----+------------+\n",
      "    |Alice|           2|\n",
      "    |  Bob|           5|\n",
      "    +-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df2.groupBy('salary').agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5fcfa14-af07-46cf-bd4a-e54acc960056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|gender|count|\n",
      "+------+-----+\n",
      "|     M|    3|\n",
      "|     F|    2|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.groupBy('gender').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd0fe1ab-ab20-4ff9-b01a-74e9063dd2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "|gender|gender_count|\n",
      "+------+------------+\n",
      "|     M|           3|\n",
      "|     F|           2|\n",
      "+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, max,min\n",
    "df2.groupBy('gender').agg(count(\"*\").alias('gender_count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0afd41df-4403-497a-b67b-fc38295e74f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+----------+----------+\n",
      "|gender|gender_count|min_salary|max_salary|\n",
      "+------+------------+----------+----------+\n",
      "|     M|           3|      3000|      4000|\n",
      "|     F|           2|        -1|      4000|\n",
      "+------+------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, max,min\n",
    "df2.groupBy('gender').agg(count(\"salary\").alias('gender_count'),\\\n",
    "                         min('salary').alias('min_salary'),\\\n",
    "                         max('salary').alias('max_salary')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "159256bc-5506-4fe1-a785-90960b05a8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+\n",
      "|firstname|middlename|lastname|       dob|gender|salary|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "|    James|          |   Smith|1991-04-01|     M|  3000|\n",
      "|  Michael|      Rose|        |2000-05-19|     M|  4000|\n",
      "|   Robert|          |Williams|1978-09-05|     M|  4000|\n",
      "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|\n",
      "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75512441-1267-4014-bf4c-aa2dcc879da4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sort' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m count, \u001b[38;5;28mmax\u001b[39m, \u001b[38;5;28mmin\u001b[39m \n\u001b[1;32m----> 2\u001b[0m df2\u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39magg(sort(count(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender_count\u001b[39m\u001b[38;5;124m'\u001b[39m)))\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sort' is not defined"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, max, min \n",
    "df2.groupBy('gender').agg(sort(count(\"*\").alias('gender_count'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9154667b-48f3-4d57-aa68-20ad32952c40",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m count\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m Solution()\n\u001b[1;32m---> 30\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mCountPairs(\u001b[38;5;241m5\u001b[39m, [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(res)\n",
      "Cell \u001b[1;32mIn[27], line 16\u001b[0m, in \u001b[0;36mSolution.CountPairs\u001b[1;34m(self, N, k, arr)\u001b[0m\n\u001b[0;32m     14\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m (N\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arr[i] \u001b[38;5;241m==\u001b[39m arr[j] \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m<\u001b[39m j \u001b[38;5;129;01mand\u001b[39;00m (i\u001b[38;5;241m+\u001b[39mj\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m%\u001b[39m k \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m :\n\u001b[0;32m     17\u001b[0m         i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     18\u001b[0m         j \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "class Solution:\n",
    "    def CountPairs(self, N, k, arr):        \n",
    "        i = 0 \n",
    "        j = N-1\n",
    "        m = 0 \n",
    "        count = 0\n",
    "        while m <= (N//2)+1:\n",
    "            if arr[i] == arr[j] and i < j and (i+j+2)% k == 0 :\n",
    "                i +=1\n",
    "                j -=1\n",
    "                m +=1\n",
    "                count += 1\n",
    "                temp = j\n",
    "            else:\n",
    "                if i == j:\n",
    "                    i +=1\n",
    "                    j = temp - 1\n",
    "                else:\n",
    "                    j -=1\n",
    "        return count\n",
    "cls = Solution()\n",
    "res = cls.CountPairs(5, [1, 2, 3, 2, 1], 3)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e96a75-8ae8-494a-bb43-1ecb6764713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 1 1 1 1 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
